{
  "ProjectId": 10,
  "ProjectName": "Monitor Integration Test",
  "JobName": "03. Reconcile Results",
  "Logging": 0,
  "LogBatchSize": 5,
  "CancelJobFlag": false,
  "LoggingType": null,
  "Tasks": [
    {
      "JobName": "03. Reconcile Results",
      "TaskContent": "# Define test case variables\r\n$TestCaseGroup = \"SQ\";\r\n$TestCases = @(\"1\", \"2\", \"3\", \"4\");\r\n\r\n# Establish database connection to Monitor Output\r\n$OutputConn = $SourceConnection.CreateOpenConnection();\r\n$ReconCheck = $OutputConn.CreateCommand();\r\n\r\n# Establish database connection to Logging database\r\n$LogConn = $TargetConnection.CreateOpenConnection();\r\n$LogOutput = $LogConn.CreateCommand();\r\n\r\n# Obtain database type of current Output connection\r\n$GetType = $OutputConn.GetType();\r\n$OutputDriverType =\r\n    switch ($GetType){\r\n        \"System.Data.SqlClient.SqlConnection\" {\"Microsoft SQL Server\"}\r\n        \"Snowflake.Data.Client.SnowflakeDbConnection\" {\"Snowflake\"}\r\n    };\r\n\r\n# Start reconciliation process with the loop on test cases\r\nForeach($TestCase in $TestCases) {\r\n    # Provide Basic Test Case information\r\n    $ProjectName = \"INTEGRATION_TEST\";\r\n    $TestCaseID = $TestCaseGroup + $TestCase;\r\n    $RuleId = -1;\r\n    \r\n    # Obtain RuleID of target Monitor Rule for related test case\r\n    $ReconCheck.CommandText = \"SELECT PROJECTID, RULEID FROM LM__REF.LM__MAPPING WHERE PROJECTNAME = '$ProjectName' AND RULENAME LIKE '$($TestCaseID + \"_%\")'\";\r\n    $RuleReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $RuleReader.Read() | Out-Null;\r\n    $RuleID = $RuleReader[\"RULEID\"];\r\n    $ProjectID = $RuleReader[\"PROJECTID\"];\r\n    \r\n    $RuleReader.Close();\r\n\r\n    # Define test variables\r\n    $ObjectPrefix = $RuleID.ToString();\r\n    $Schema = \"LM__$ProjectID\";\r\n    $MetadataCols = \"'TaskExecutionId','LoadDateTime','DgRowHash','DGStartDate','PersistDeleted'\";\r\n    $ExpectedKeyCol = switch ($TestCaseID) {\r\n        {($_ -eq \"SQ1\") -or ($_ -eq \"SQ2\")} {\"'AccountKey'\"}\r\n        {($_ -eq \"SQ3\") -or ($_ -eq \"SQ4\")} {\"'OrderID'\"}\r\n    };\r\n    $ExpectedCol = switch ($TestCaseID) {\r\n        \"SQ1\" {\"'AccountKey','ParentAccountKey','AccountDescription','AccountType','Operator','ValueType','ActiveStatus'\"}\r\n        \"SQ2\" {\"'AccountKey','AccountDescription','AccountType','Operator','ValueType'\"}\r\n        \"SQ3\" {\"'OrderID','LineCount','OrderQtyTotal','OrderTotal','AveragePerUnit','TotalBeforeDiscount'\"}\r\n        \"SQ4\" {\"'Mth','OrderID','LineCount','OrderTotal'\"}\r\n    };\r\n    $OutputTable = \"[$Schema].[LM__$($ObjectPrefix + \"__RESULTS\")]\";\r\n    $ERTable = \"[Monitor].[Monitor_$($TestCaseID)_ER]\";\r\n\r\n    # Convert test variables for Snowflake Output\r\n    if ($OutputDriverType -eq \"Snowflake\") {\r\n        $Schema = $Schema.ToUpper();\r\n        $MetadataCols = $MetadataCols.ToUpper();\r\n        $ExpectedKeyCol = $ExpectedKeyCol.ToUpper();\r\n        $ExpectedCol = $ExpectedCol.ToUpper();\r\n        $OutputTable = $OutputTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $ERTable = \"\"\"Monitor\"\".\"\"MONITOR_$($TestCaseID)_ER\"\"\";\r\n    }\r\n    \r\n    # Define expected result reference\r\n    $RefObjectCount = 13;\r\n    $RefKeyColNum = 1;\r\n    $RefColNum = switch ($TestCaseID) {\r\n        \"SQ1\" {7}\r\n        \"SQ2\" {5}\r\n        \"SQ3\" {6}\r\n        \"SQ4\" {4}\r\n    };\r\n    \r\n    #Default check result variables to 0\r\n    $ObjectCheckResult = 0;\r\n    $KeyColCheckResult = 0;\r\n    $ColCheckResult = 0;\r\n    $DataCheckResult = 0;\r\n    \r\n    # Attempt to check if all related persistent staging objects were created in Monitor Output\r\n    $ReconCheck.CommandText = switch ($OutputDriverType) {\r\n        \"Snowflake\" {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"\\\\__%\")' ESCAPE '\\\\'\"}\r\n        default {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"__%\")'\"}\r\n    };\r\n    $ObjectReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $ObjectReader.Read() | Out-Null;\r\n    $ObjectCount = $ObjectReader[\"OBJ_AMOUNT\"];\r\n    \r\n    $ObjectReader.Close();\r\n    \r\n    # Mark object check to fail if the amount of persistent staging objects do not match expected number\r\n    If ($ObjectCount -ne $RefObjectCount)\r\n    {\r\n        $ObjectCheckResult = 1;\r\n    } else {\r\n        # Attempt to check if key columns are captured as expected\r\n        $ReconCheck.CommandText = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '$Schema' AND TABLE_NAME = 'LM__$($ObjectPrefix + \"__METADATA\")' AND COLUMN_NAME NOT LIKE 'LM__%' AND COLUMN_NAME NOT IN ($MetadataCols)\";\r\n        $KeyColReader = $ReconCheck.ExecuteReader();\r\n        \r\n        $KeyColCount = 0;\r\n        $KeyColVariance = $ExpectedKeyCol;\r\n        While ($KeyColReader.Read()) {\r\n            $KeyColVariance = $KeyColVariance.Replace(\"'\" + $KeyColReader[\"COLUMN_NAME\"] + \"'\", \"\");\r\n            $KeyColCount += 1;\r\n        }\r\n        $KeyColVariance = $KeyColVariance.Replace(\",\", \"\");\r\n        \r\n        $KeyColReader.Close();\r\n\r\n        # Mark key column check to fail if the key columns stored in metadata not meet expectation\r\n        If ($KeyColVariance -ne \"\" -or $KeyColCount -ne $RefKeyColNum) {\r\n            $KeyColCheckResult = 1;\r\n        } else {\r\n            # Attempt to check if data columns are loaded to Output as expected\r\n            $ReconCheck.CommandText = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '$Schema' AND TABLE_NAME = 'LM__$($ObjectPrefix + \"__DATA\")' AND COLUMN_NAME NOT LIKE 'LM__%' AND COLUMN_NAME NOT IN ($MetadataCols)\";\r\n            $ColReader = $ReconCheck.ExecuteReader();\r\n            \r\n            $ColCount = 0;\r\n            $ColVariance = $ExpectedCol;\r\n            While ($ColReader.Read()) {\r\n                $ColVariance = $ColVariance.Replace(\"'\" + $ColReader[\"COLUMN_NAME\"] + \"'\", \"\");\r\n                $ColCount += 1;\r\n            }\r\n            $ColVariance = $ColVariance.Replace(\",\", \"\");\r\n            \r\n            $ColReader.Close();\r\n            \r\n            # Mark column check to fail if the columns loaded to Output not meet expectation\r\n            If ($ColVariance -ne \"\" -or $ColCount -ne $RefColNum) {\r\n                $ColCheckResult = 1;\r\n            } else {\r\n                # Attempt to check if loaded data and status can match expected results\r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $OutputTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable) Src\";\r\n                $ResultReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ResultReconReader.Read() | Out-Null;\r\n                $ResultVarianceCount = $ResultReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ResultReconReader.Close();\r\n                \r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $OutputTable) Src\";\r\n                $ERReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ERReconReader.Read() | Out-Null;\r\n                $ERVarianceCount = $ERReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ERReconReader.Close();\r\n            \r\n                # Mark data check to fail if the data or status not meet expectation\r\n                If (($ERVarianceCount -ne 0) -and ($ResultVarianceCount -ne 0)) {\r\n                    $DataCheckResult = 1;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    # Obtain result from above checks\r\n    $ActualResult = $ObjectCheckResult + $KeyColCheckResult + $ColCheckResult + $DataCheckResult;\r\n\r\n    # Obtain designed result from test case reference\r\n    $LogOutput.CommandText = \"SELECT DesignedResult FROM Monitor.MonitorTestReference WHERE TestCaseID = '$TestCaseID'\";\r\n    $ResultReader = $LogOutput.ExecuteReader();\r\n    \r\n    $ResultReader.Read() | Out-Null;\r\n    $DesignedResult = $ResultReader[\"DesignedResult\"];\r\n    \r\n    $ResultReader.Close();\r\n    \r\n    # Compare actual result to designed result, output the test result and error description (if any)\r\n    If ($ActualResult -eq $DesignedResult) {\r\n        $TestResult = \"Pass\";\r\n        $ErrorDesc = \"\";\r\n    } else {\r\n        $TestResult = \"Fail\";\r\n        $ErrorDesc = switch ($true) {\r\n            {($ObjectCheckResult -eq 1)} {\"Cannot find all expected tables and views from persistent staging process for test case $TestCaseID.\"}\r\n            {($KeyColCheckResult -eq 1)} {\"Key Column(s) found in the Metadata table does not meet expectation.\"}\r\n            {($ColCheckResult -eq 1)} {\"Columns found in the Data table does not meet expectation.\"}\r\n            {($DataCheckResult -eq 1)} {\"Found variance on data compare to the Expected Result data set.\"}\r\n        };\r\n    }\r\n    \r\n    # Output execution result to log\r\n    $ExecutionDatetime = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\";\r\n    \r\n    $LogOutput.CommandText = \"INSERT INTO [Monitor].[TestLog] (ExecutionDatetime, OutputConnection, TestCaseID, TestResult, ErrorDescription) VALUES (CAST('\" + $ExecutionDatetime + \"' AS datetime), '\" + $SourceConnection.Options.ConnectionId + \"', '\" + $TestCaseID + \"', '\" + $TestResult + \"', '\" + $ErrorDesc + \"')\";\r\n    $LogOutput.ExecuteNonQuery() | Out-Null;\r\n}\r\n\r\n# Close connections\r\n$OutputConn.Close();\r\n$LogConn.Close();",
      "TaskName": "SQ - Reconcile with Expected Output Results",
      "ProjectId": 10,
      "ProjectName": null,
      "TaskTypeName": "PowerShell Core",
      "Logging": 1,
      "LastEndPoint": null,
      "PendingEndPoint": null,
      "ParameterNames": "",
      "ParameterDefaults": "",
      "SourceSchema": null,
      "TargetSchema": null,
      "SourceConnectionName": "Monitor Snowflake Output",
      "TargetConnectionName": "Regression Test Logging",
      "SourceFileName": null,
      "TargetFileName": null,
      "SourceClusterName": null,
      "TargetClusterName": null,
      "SourceFileId": null,
      "TargetFileId": null,
      "MaxThreads": 4,
      "ParallelDm": true,
      "PythonEnvironmentName": null,
      "RunWithAgentId": 2,
      "Agent": {
        "AgentId": 2,
        "AgentName": "PerPrd-WEB01.bizdata.local",
        "HostName": "PerPrd-WEB01.bizdata.local",
        "DateCreated": "0001-01-01T00:00:00",
        "DateUpdated": "0001-01-01T00:00:00",
        "HeartBeat": "0001-01-01T00:00:00",
        "Version": null,
        "TaskQueues": null,
        "ConnectionId": null,
        "IsHealthy": false
      },
      "PythonEnvironment": null,
      "SourceConnection": null,
      "TargetConnection": null,
      "SourceCluster": null,
      "TargetCluster": null,
      "LoggingType": null,
      "TaskType": null,
      "TaskTable": [],
      "TaskConnections": []
    },
    {
      "JobName": "03. Reconcile Results",
      "TaskContent": "# Define test case variables\r\n$TestCaseGroup = \"KC\";\r\n$TestCases = @(\"1\");\r\n\r\n# Establish database connection to Monitor Output\r\n$OutputConn = $SourceConnection.CreateOpenConnection();\r\n$ReconCheck = $OutputConn.CreateCommand();\r\n\r\n# Establish database connection to Logging database\r\n$LogConn = $TargetConnection.CreateOpenConnection();\r\n$LogOutput = $LogConn.CreateCommand();\r\n\r\n# Obtain database type of current Output connection\r\n$GetType = $OutputConn.GetType();\r\n$OutputDriverType =\r\n    switch ($GetType){\r\n        \"System.Data.SqlClient.SqlConnection\" {\"Microsoft SQL Server\"}\r\n        \"Snowflake.Data.Client.SnowflakeDbConnection\" {\"Snowflake\"}\r\n    };\r\n\r\n# Start reconciliation process with the loop on test cases\r\nForeach($TestCase in $TestCases) {\r\n    # Provide Basic Test Case information\r\n    $ProjectName = \"INTEGRATION_TEST\";\r\n    $TestCaseID = $TestCaseGroup + $TestCase;\r\n    $RuleId = -1;\r\n    \r\n    # Obtain RuleID of target Monitor Rule for related test case\r\n    $ReconCheck.CommandText = \"SELECT PROJECTID, RULEID FROM LM__REF.LM__MAPPING WHERE PROJECTNAME = '$ProjectName' AND RULENAME LIKE '$($TestCaseID + \"_%\")'\";\r\n    $RuleReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $RuleReader.Read() | Out-Null;\r\n    $RuleID = $RuleReader[\"RULEID\"];\r\n    $ProjectID = $RuleReader[\"PROJECTID\"];\r\n    \r\n    $RuleReader.Close();\r\n\r\n    # Define test variables\r\n    $ObjectPrefix = $RuleID.ToString();\r\n    $Schema = \"LM__$ProjectID\";\r\n    $MetadataCols = \"'TaskExecutionId','LoadDateTime','DgRowHash','DGStartDate','PersistDeleted'\";\r\n    $ExpectedKeyCol = switch ($TestCaseID) {\r\n        \"KC1\" {\"'TargetConnection','TestCaseID'\"}\r\n    };\r\n    $ExpectedCol = switch ($TestCaseID) {\r\n        \"KC1\" {\"'TargetConnection','TestCaseID','TestResult','ExecutionDatetime'\"}\r\n    };\r\n    $OutputTable = \"[$Schema].[LM__$($ObjectPrefix + \"__RESULTS\")]\";\r\n    $ERTable = \"[Monitor].[Monitor_$($TestCaseID)_ER]\";\r\n\r\n    # Convert test variables for Snowflake Output\r\n    if ($OutputDriverType -eq \"Snowflake\") {\r\n        $Schema = $Schema.ToUpper();\r\n        $MetadataCols = $MetadataCols.ToUpper();\r\n        $ExpectedKeyCol = $ExpectedKeyCol.ToUpper();\r\n        $ExpectedCol = $ExpectedCol.ToUpper();\r\n        $OutputTable = $OutputTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $ERTable = \"\"\"Monitor\"\".\"\"MONITOR_$($TestCaseID)_ER\"\"\";\r\n    }\r\n\r\n    # Define expected result reference\r\n    $RefObjectCount = 13;\r\n    $RefKeyColNum = 2;\r\n    $RefColNum = 4;\r\n\r\n    #Default check result variables to 0\r\n    $ObjectCheckResult = 0;\r\n    $KeyColCheckResult = 0;\r\n    $ColCheckResult = 0;\r\n    $DataCheckResult = 0;\r\n    \r\n    # Attempt to check if all related persistent staging objects were created in Monitor Output\r\n    $ReconCheck.CommandText = switch ($OutputDriverType) {\r\n        \"Snowflake\" {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"\\\\__%\")' ESCAPE '\\\\'\"}\r\n        default {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"__%\")'\"}\r\n    };\r\n    $ObjectReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $ObjectReader.Read() | Out-Null;\r\n    $ObjectCount = $ObjectReader[\"OBJ_AMOUNT\"];\r\n    \r\n    $ObjectReader.Close();\r\n    \r\n    # Mark object check to fail if the amount of persistent staging objects do not match expected number\r\n    If ($ObjectCount -ne $RefObjectCount)\r\n    {\r\n        $ObjectCheckResult = 1;\r\n    } else {\r\n        # Attempt to check if key columns are captured as expected\r\n        $ReconCheck.CommandText = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '$Schema' AND TABLE_NAME = 'LM__$($ObjectPrefix + \"__METADATA\")' AND COLUMN_NAME NOT LIKE 'LM__%' AND COLUMN_NAME NOT IN ($MetadataCols)\";\r\n        $KeyColReader = $ReconCheck.ExecuteReader();\r\n        \r\n        $KeyColCount = 0;\r\n        $KeyColVariance = $ExpectedKeyCol;\r\n        While ($KeyColReader.Read()) {\r\n            $KeyColVariance = $KeyColVariance.Replace(\"'\" + $KeyColReader[\"COLUMN_NAME\"] + \"'\", \"\");\r\n            $KeyColCount += 1;\r\n        }\r\n        $KeyColVariance = $KeyColVariance.Replace(\",\", \"\");\r\n        \r\n        $KeyColReader.Close();\r\n\r\n        # Mark key column check to fail if the key columns stored in metadata not meet expectation\r\n        If ($KeyColVariance -ne \"\" -or $KeyColCount -ne $RefKeyColNum) {\r\n            $KeyColCheckResult = 1;\r\n        } else {\r\n            # Attempt to check if data columns are loaded to Output as expected\r\n            $ReconCheck.CommandText = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '$Schema' AND TABLE_NAME = 'LM__$($ObjectPrefix + \"__DATA\")' AND COLUMN_NAME NOT LIKE 'LM__%' AND COLUMN_NAME NOT IN ($MetadataCols)\";\r\n            $ColReader = $ReconCheck.ExecuteReader();\r\n\r\n            $ColCount = 0;\r\n            $ColVariance = $ExpectedCol;\r\n            While ($ColReader.Read()) {\r\n                $ColVariance = $ColVariance.Replace(\"'\" + $ColReader[\"COLUMN_NAME\"] + \"'\", \"\");\r\n                $ColCount += 1;\r\n            }\r\n            $ColVariance = $ColVariance.Replace(\",\", \"\");\r\n\r\n            $ColReader.Close();\r\n\r\n            # Mark column check to fail if the columns loaded to Output not meet expectation\r\n            If ($ColVariance -ne \"\" -or $ColCount -ne $RefColNum) {\r\n                $ColCheckResult = 1;\r\n            } else {\r\n                # Attempt to check if loaded data and status can match expected results\r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $OutputTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable) Src\";\r\n                $ResultReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ResultReconReader.Read() | Out-Null;\r\n                $ResultVarianceCount = $ResultReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ResultReconReader.Close();\r\n                \r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $OutputTable) Src\";\r\n                $ERReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ERReconReader.Read() | Out-Null;\r\n                $ERVarianceCount = $ERReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ERReconReader.Close();\r\n\r\n                # Mark data check to fail if the data or status not meet expectation\r\n                If (($ERVarianceCount -ne 0) -and ($ResultVarianceCount -ne 0)) {\r\n                    $DataCheckResult = 1;\r\n                }\r\n            }\r\n        }        \r\n    }\r\n\r\n    # Obtain result from above checks\r\n    $ActualResult = $ObjectCheckResult + $KeyColCheckResult + $ColCheckResult + $DataCheckResult;\r\n\r\n    # Obtain designed result from test case reference\r\n    $LogOutput.CommandText = \"SELECT DesignedResult FROM Monitor.MonitorTestReference WHERE TestCaseID = '$TestCaseID'\";\r\n    $ResultReader = $LogOutput.ExecuteReader();\r\n    \r\n    $ResultReader.Read() | Out-Null;\r\n    $DesignedResult = $ResultReader[\"DesignedResult\"];\r\n    \r\n    $ResultReader.Close();\r\n    \r\n    # Compare actual result to designed result, output the test result and error description (if any)\r\n    If ($ActualResult -eq $DesignedResult) {\r\n        $TestResult = \"Pass\";\r\n        $ErrorDesc = \"\";\r\n    } else {\r\n        $TestResult = \"Fail\";\r\n        $ErrorDesc = switch ($true) {\r\n            {($ObjectCheckResult -eq 1)} {\"Cannot find all expected tables and views from persistent staging process for test case $TestCaseID.\"}\r\n            {($KeyColCheckResult -eq 1)} {\"Key Column(s) found in the Metadata table does not meet expectation.\"}\r\n            {($ColCheckResult -eq 1)} {\"Columns found in the Data table does not meet expectation.\"}\r\n            {($DataCheckResult -eq 1)} {\"Found variance on data compare to the Expected Result data set.\"}\r\n        };\r\n    }\r\n\r\n    # Output execution result to log\r\n    $ExecutionDatetime = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\";\r\n    \r\n    $LogOutput.CommandText = \"INSERT INTO [Monitor].[TestLog] (ExecutionDatetime, OutputConnection, TestCaseID, TestResult, ErrorDescription) VALUES (CAST('\" + $ExecutionDatetime + \"' AS datetime), '\" + $SourceConnection.Options.ConnectionId + \"', '\" + $TestCaseID + \"', '\" + $TestResult + \"', '\" + $ErrorDesc + \"')\";\r\n    $LogOutput.ExecuteNonQuery() | Out-Null;\r\n}\r\n\r\n# Close connections\r\n$OutputConn.Close();\r\n$LogConn.Close();",
      "TaskName": "KC - Reconcile with Expected Output Results",
      "ProjectId": 10,
      "ProjectName": null,
      "TaskTypeName": "PowerShell Core",
      "Logging": 1,
      "LastEndPoint": null,
      "PendingEndPoint": null,
      "ParameterNames": "",
      "ParameterDefaults": "",
      "SourceSchema": null,
      "TargetSchema": null,
      "SourceConnectionName": "Monitor Snowflake Output",
      "TargetConnectionName": "Regression Test Logging",
      "SourceFileName": null,
      "TargetFileName": null,
      "SourceClusterName": null,
      "TargetClusterName": null,
      "SourceFileId": null,
      "TargetFileId": null,
      "MaxThreads": 4,
      "ParallelDm": true,
      "PythonEnvironmentName": null,
      "RunWithAgentId": 2,
      "Agent": {
        "AgentId": 2,
        "AgentName": "PerPrd-WEB01.bizdata.local",
        "HostName": "PerPrd-WEB01.bizdata.local",
        "DateCreated": "0001-01-01T00:00:00",
        "DateUpdated": "0001-01-01T00:00:00",
        "HeartBeat": "0001-01-01T00:00:00",
        "Version": null,
        "TaskQueues": null,
        "ConnectionId": null,
        "IsHealthy": false
      },
      "PythonEnvironment": null,
      "SourceConnection": null,
      "TargetConnection": null,
      "SourceCluster": null,
      "TargetCluster": null,
      "LoggingType": null,
      "TaskType": null,
      "TaskTable": [],
      "TaskConnections": []
    },
    {
      "JobName": "03. Reconcile Results",
      "TaskContent": "# Define test case variables\r\n$TestCaseGroup = \"RR\";\r\n$TestCases = @(\"1\",\"2\");\r\n\r\n# Establish database connection to Monitor Output\r\n$OutputConn = $SourceConnection.CreateOpenConnection();\r\n$ReconCheck = $OutputConn.CreateCommand();\r\n\r\n# Establish database connection to Logging database\r\n$LogConn = $TargetConnection.CreateOpenConnection();\r\n$LogOutput = $LogConn.CreateCommand();\r\n\r\n# Obtain database type of current Output connection\r\n$GetType = $OutputConn.GetType();\r\n$OutputDriverType =\r\n    switch ($GetType){\r\n        \"System.Data.SqlClient.SqlConnection\" {\"Microsoft SQL Server\"}\r\n        \"Snowflake.Data.Client.SnowflakeDbConnection\" {\"Snowflake\"}\r\n    };\r\n\r\n# Start reconciliation process with the loop on test cases\r\nForeach($TestCase in $TestCases) {\r\n    # Provide Basic Test Case information\r\n    $ProjectName = \"INTEGRATION_TEST\";\r\n    $TestCaseID = $TestCaseGroup + $TestCase;\r\n    $RuleId = -1;\r\n    \r\n    # Obtain RuleID of target Monitor Rule for related test case\r\n    $ReconCheck.CommandText = \"SELECT PROJECTID, RULEID FROM LM__REF.LM__MAPPING WHERE PROJECTNAME = '$ProjectName' AND RULENAME LIKE '$($TestCaseID + \"_%\")'\";\r\n    $RuleReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $RuleReader.Read() | Out-Null;\r\n    $RuleID = $RuleReader[\"RULEID\"];\r\n    $ProjectID = $RuleReader[\"PROJECTID\"];\r\n    \r\n    $RuleReader.Close();\r\n\r\n    # Define test variables\r\n    $ObjectPrefix = $RuleID.ToString();\r\n    $Schema = \"LM__$ProjectID\";\r\n    $MetadataCols = \"'TaskExecutionId','LoadDateTime','DgRowHash','DGStartDate','PersistDeleted'\";\r\n    $ExpectedKeyCol = switch ($TestCaseID) {\r\n        \"RR1\" {\"'OrderDetailID'\"}\r\n        \"RR2\" {\"'TargetConnection','TestCaseID'\"}\r\n    };\r\n    $ExpectedCol = switch ($TestCaseID) {\r\n        \"RR1\" {\"'OrderID','OrderDetailID','ProductID','OrderQty','TransactionDate'\"}\r\n        \"RR2\" {\"'TargetConnection','TestCaseID','TestResult','ExecutionDatetime'\"}\r\n    };\r\n    $OutputTable = \"[$Schema].[LM__$($ObjectPrefix + \"__RESULTS\")]\";\r\n    $ERTable = \"[Monitor].[Monitor_$($TestCaseID)_ER]\";\r\n\r\n    # Convert test variables for Snowflake Output\r\n    if ($OutputDriverType -eq \"Snowflake\") {\r\n        $Schema = $Schema.ToUpper();\r\n        $MetadataCols = $MetadataCols.ToUpper();\r\n        $ExpectedKeyCol = $ExpectedKeyCol.ToUpper();\r\n        $ExpectedCol = $ExpectedCol.ToUpper();\r\n        $OutputTable = $OutputTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $ERTable = \"\"\"Monitor\"\".\"\"MONITOR_$($TestCaseID)_ER\"\"\";\r\n    }\r\n\r\n    # Define expected result reference\r\n    $RefObjectCount = 13;\r\n    $RefKeyColNum = switch ($TestCaseID) {\r\n        \"RR1\" {1}\r\n        \"RR2\" {2}\r\n    };\r\n    $RefColNum = switch ($TestCaseID) {\r\n        \"RR1\" {5}\r\n        \"RR2\" {4}\r\n    };\r\n\r\n    #Default check result variables to 0\r\n    $ObjectCheckResult = 0;\r\n    $KeyColCheckResult = 0;\r\n    $ColCheckResult = 0;\r\n    $DataCheckResult = 0;\r\n    \r\n    # Attempt to check if all related persistent staging objects were created in Monitor Output\r\n    $ReconCheck.CommandText = switch ($OutputDriverType) {\r\n        \"Snowflake\" {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"\\\\__%\")' ESCAPE '\\\\'\"}\r\n        default {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"__%\")'\"}\r\n    };\r\n    $ObjectReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $ObjectReader.Read() | Out-Null;\r\n    $ObjectCount = $ObjectReader[\"OBJ_AMOUNT\"];\r\n    \r\n    $ObjectReader.Close();\r\n    \r\n    # Mark object check to fail if the amount of persistent staging objects do not match expected number\r\n    If ($ObjectCount -ne $RefObjectCount)\r\n    {\r\n        $ObjectCheckResult = 1;\r\n    } else {\r\n        # Attempt to check if key columns are captured as expected\r\n        $ReconCheck.CommandText = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '$Schema' AND TABLE_NAME = 'LM__$($ObjectPrefix + \"__METADATA\")' AND COLUMN_NAME NOT LIKE 'LM__%' AND COLUMN_NAME NOT IN ($MetadataCols)\";\r\n        $KeyColReader = $ReconCheck.ExecuteReader();\r\n        \r\n        $KeyColCount = 0;\r\n        $KeyColVariance = $ExpectedKeyCol;\r\n        While ($KeyColReader.Read()) {\r\n            $KeyColVariance = $KeyColVariance.Replace(\"'\" + $KeyColReader[\"COLUMN_NAME\"] + \"'\", \"\");\r\n            $KeyColCount += 1;\r\n        }\r\n        $KeyColVariance = $KeyColVariance.Replace(\",\", \"\");\r\n        \r\n        $KeyColReader.Close();\r\n\r\n        # Mark key column check to fail if the key columns stored in metadata not meet expectation\r\n        If ($KeyColVariance -ne \"\" -or $KeyColCount -ne $RefKeyColNum) {\r\n            $KeyColCheckResult = 1;\r\n        } else {\r\n            # Attempt to check if data columns are loaded to Output as expected\r\n            $ReconCheck.CommandText = \"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_SCHEMA = '$Schema' AND TABLE_NAME = 'LM__$($ObjectPrefix + \"__DATA\")' AND COLUMN_NAME NOT LIKE 'LM__%' AND COLUMN_NAME NOT IN ($MetadataCols)\";\r\n            $ColReader = $ReconCheck.ExecuteReader();\r\n\r\n            $ColCount = 0;\r\n            $ColVariance = $ExpectedCol;\r\n            While ($ColReader.Read()) {\r\n                $ColVariance = $ColVariance.Replace(\"'\" + $ColReader[\"COLUMN_NAME\"] + \"'\", \"\");\r\n                $ColCount += 1;\r\n            }\r\n            $ColVariance = $ColVariance.Replace(\",\", \"\");\r\n\r\n            $ColReader.Close();\r\n\r\n            # Mark column check to fail if the columns loaded to Output not meet expectation\r\n            If ($ColVariance -ne \"\" -or $ColCount -ne $RefColNum) {\r\n                $ColCheckResult = 1;\r\n            } else {\r\n                # Attempt to check if loaded data and status can match expected results\r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $OutputTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable) Src\";\r\n                $ResultReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ResultReconReader.Read() | Out-Null;\r\n                $ResultVarianceCount = $ResultReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ResultReconReader.Close();\r\n                \r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $OutputTable) Src\";\r\n                $ERReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ERReconReader.Read() | Out-Null;\r\n                $ERVarianceCount = $ERReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ERReconReader.Close();\r\n\r\n                # Mark data check to fail if the data or status not meet expectation\r\n                If (($ERVarianceCount -ne 0) -and ($ResultVarianceCount -ne 0)) {\r\n                    $DataCheckResult = 1;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    # Obtain result from above checks\r\n    $ActualResult = $ObjectCheckResult + $KeyColCheckResult + $ColCheckResult + $DataCheckResult;\r\n\r\n    # Obtain designed result from test case reference\r\n    $LogOutput.CommandText = \"SELECT DesignedResult FROM Monitor.MonitorTestReference WHERE TestCaseID = '$TestCaseID'\";\r\n    $ResultReader = $LogOutput.ExecuteReader();\r\n    \r\n    $ResultReader.Read() | Out-Null;\r\n    $DesignedResult = $ResultReader[\"DesignedResult\"];\r\n    \r\n    $ResultReader.Close();\r\n    \r\n    # Compare actual result to designed result, output the test result and error description (if any)\r\n    If ($ActualResult -eq $DesignedResult) {\r\n        $TestResult = \"Pass\";\r\n        $ErrorDesc = \"\";\r\n    } else {\r\n        $TestResult = \"Fail\";\r\n        $ErrorDesc = switch ($true) {\r\n            {($ObjectCheckResult -eq 1)} {\"Cannot find all expected tables and views from persistent staging process for test case $TestCaseID.\"}\r\n            {($KeyColCheckResult -eq 1)} {\"Key Column(s) found in the Metadata table does not meet expectation.\"}\r\n            {($ColCheckResult -eq 1)} {\"Columns found in the Data table does not meet expectation.\"}\r\n            {($DataCheckResult -eq 1)} {\"Found variance on data compare to the Expected Result data set.\"}\r\n        };\r\n    }\r\n\r\n    # Output execution result to log\r\n    $ExecutionDatetime = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\";\r\n    \r\n    $LogOutput.CommandText = \"INSERT INTO [Monitor].[TestLog] (ExecutionDatetime, OutputConnection, TestCaseID, TestResult, ErrorDescription) VALUES (CAST('\" + $ExecutionDatetime + \"' AS datetime), '\" + $SourceConnection.Options.ConnectionId + \"', '\" + $TestCaseID + \"', '\" + $TestResult + \"', '\" + $ErrorDesc + \"')\";\r\n    $LogOutput.ExecuteNonQuery() | Out-Null;\r\n}\r\n\r\n# Close connections\r\n$OutputConn.Close();\r\n$LogConn.Close();",
      "TaskName": "RR - Reconcile with Expected Output Results",
      "ProjectId": 10,
      "ProjectName": null,
      "TaskTypeName": "PowerShell Core",
      "Logging": 1,
      "LastEndPoint": null,
      "PendingEndPoint": null,
      "ParameterNames": "",
      "ParameterDefaults": "",
      "SourceSchema": null,
      "TargetSchema": null,
      "SourceConnectionName": "Monitor Snowflake Output",
      "TargetConnectionName": "Regression Test Logging",
      "SourceFileName": null,
      "TargetFileName": null,
      "SourceClusterName": null,
      "TargetClusterName": null,
      "SourceFileId": null,
      "TargetFileId": null,
      "MaxThreads": 4,
      "ParallelDm": true,
      "PythonEnvironmentName": null,
      "RunWithAgentId": 2,
      "Agent": {
        "AgentId": 2,
        "AgentName": "PerPrd-WEB01.bizdata.local",
        "HostName": "PerPrd-WEB01.bizdata.local",
        "DateCreated": "0001-01-01T00:00:00",
        "DateUpdated": "0001-01-01T00:00:00",
        "HeartBeat": "0001-01-01T00:00:00",
        "Version": null,
        "TaskQueues": null,
        "ConnectionId": null,
        "IsHealthy": false
      },
      "PythonEnvironment": null,
      "SourceConnection": null,
      "TargetConnection": null,
      "SourceCluster": null,
      "TargetCluster": null,
      "LoggingType": null,
      "TaskType": null,
      "TaskTable": [],
      "TaskConnections": []
    },
    {
      "JobName": "03. Reconcile Results",
      "TaskContent": "# Define test case variables\r\n$TestCaseGroup = \"PSTG\";\r\n$TestCases = @(\"1\", \"2\", \"3\", \"4\");\r\n\r\n# Establish database connection to Monitor Output\r\n$OutputConn = $SourceConnection.CreateOpenConnection();\r\n$ReconCheck = $OutputConn.CreateCommand();\r\n\r\n# Establish database connection to Logging database\r\n$LogConn = $TargetConnection.CreateOpenConnection();\r\n$LogOutput = $LogConn.CreateCommand();\r\n\r\n# Obtain database type of current Output connection\r\n$GetType = $OutputConn.GetType();\r\n$OutputDriverType =\r\n    switch ($GetType){\r\n        \"System.Data.SqlClient.SqlConnection\" {\"Microsoft SQL Server\"}\r\n        \"Snowflake.Data.Client.SnowflakeDbConnection\" {\"Snowflake\"}\r\n    };\r\n\r\n# Start reconciliation process with the loop on test cases\r\nForeach($TestCase in $TestCases) {\r\n    # Provide Basic Test Case information\r\n    $ProjectName = \"INTEGRATION_TEST\";\r\n    $TestCaseID = $TestCaseGroup + $TestCase;\r\n    $RuleId = -1;\r\n    \r\n    # Obtain RuleID of target Monitor Rule for related test case\r\n    $ReconCheck.CommandText = \"SELECT PROJECTID, RULEID FROM LM__REF.LM__MAPPING WHERE ProjectName = '$ProjectName' AND RuleName LIKE '$($TestCaseID + \"_%\")'\";\r\n    $RuleReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $RuleReader.Read() | Out-Null;\r\n    $RuleID = $RuleReader[\"RULEID\"];\r\n    $ProjectID = $RuleReader[\"PROJECTID\"];\r\n    \r\n    $RuleReader.Close();\r\n\r\n    # Define test variables\r\n    $ObjectPrefix = $RuleID.ToString();\r\n    $Schema = \"LM__$ProjectID\";\r\n    $StgSchema = \"DGStg\";\r\n    $MetadataCols = \"'TaskExecutionId','LoadDateTime','DgRowHash','DGStartDate','PersistDeleted'\";\r\n    $ExpectedCol = \"'AccountBK','ParentAccountBK','AccountDescription','AccountType','Operator','ValueType'\";\r\n    $ResultTable = \"[$Schema].[LM__$($ObjectPrefix + \"__RESULTS\")]\";\r\n    $DataHisTable = \"[$Schema].[LM__$($ObjectPrefix + \"__DATAHistory\")]\";\r\n    $DataCurTable = \"[$Schema].[LM__$($ObjectPrefix + \"__DATACurrent\")]\";\r\n    $ERTable = \"[Monitor].[Monitor_$($TestCaseID)_ER]\";\r\n\r\n    # Convert test variables for Snowflake Output\r\n    if ($OutputDriverType -eq \"Snowflake\") {\r\n        $Schema = $Schema.ToUpper();\r\n        $StgSchema = '\"' + $StgSchema + '\"';\r\n        $MetadataCols = $MetadataCols.ToUpper();\r\n        $ExpectedCol = $ExpectedCol.ToUpper();\r\n        $ResultTable = $ResultTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $DataHisTable = $DataHisTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $DataCurTable = $DataCurTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $ERTable = \"\"\"Monitor\"\".\"\"MONITOR_$($TestCaseID)_ER\"\"\";\r\n    }\r\n\r\n    # Define expected result reference\r\n    $RefObjectCount = 13;\r\n    $RefAccountCount = 3;\r\n    $RefRowCount = switch ($TestCaseID) {\r\n        \"PSTG1\" {3}\r\n        \"PSTG2\" {6}\r\n        \"PSTG3\" {9}\r\n        \"PSTG4\" {6}\r\n    };\r\n    $RefPstgDelCount = switch ($TestCaseID) {\r\n        {$_ -eq \"PSTG1\" -or $_ -eq \"PSTG4\"} {0}\r\n        {$_ -eq \"PSTG2\" -or $_ -eq \"PSTG3\"} {3}\r\n    };\r\n    $RefDataDateMatched = switch ($TestCaseID) {\r\n        {$_ -eq \"PSTG1\" -or $_ -eq \"PSTG3\" -or $_ -eq \"PSTG4\"} {3}\r\n        \"PSTG2\" {0}\r\n    };\r\n    $RefMetadataDateMatched = switch ($TestCaseID) {\r\n        \"PSTG1\" {3}\r\n        {$_ -eq \"PSTG2\" -or $_ -eq \"PSTG3\" -or $_ -eq \"PSTG4\"} {0}\r\n    };\r\n\r\n    #Default check result variables to 0\r\n    $ObjectCheckResult = 0;\r\n    $PStgCheckResult = 0;\r\n    $DateMatchedCheckResult = 0;\r\n    $DataCheckResult = 0;\r\n    \r\n    # Attempt to check if all related persistent staging objects were created in Monitor Output\r\n    $ReconCheck.CommandText = switch ($OutputDriverType) {\r\n        \"Snowflake\" {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"\\\\__%\")' ESCAPE '\\\\'\"}\r\n        default {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"__%\")'\"}\r\n    };\r\n    $ObjectReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $ObjectReader.Read() | Out-Null;\r\n    $ObjectCount = $ObjectReader[\"OBJ_AMOUNT\"];\r\n    \r\n    $ObjectReader.Close();\r\n\r\n    # Mark object check to fail if the amount of persistent staging objects do not match expected number\r\n    If ($ObjectCount -ne $RefObjectCount)\r\n    {\r\n        $ObjectCheckResult = 1;\r\n    } else {\r\n        # Attempt to check if Persistent Staging process has generated relevant rows as we expect\r\n        $ReconCheck.CommandText = \"SELECT COUNT(DISTINCT c.AccountBK) AS ACC_COUNT, COUNT(*) AS ROW_COUNT, SUM(CAST(PersistDeleted AS INT)) AS DELETE_COUNT FROM $DataHisTable h INNER JOIN (SELECT AccountBK FROM $DataCurTable WHERE StartDate = (SELECT MAX(StartDate) FROM $DataCurTable)) c ON h.AccountBK = c.AccountBK\";\r\n        $PStgReader = $ReconCheck.ExecuteReader();\r\n        \r\n        While ($PStgReader.Read()) {\r\n            $AccountCount = $PStgReader[\"ACC_COUNT\"];\r\n            $RowCount = $PStgReader[\"ROW_COUNT\"];\r\n            $PStgDelCount = $PStgReader[\"DELETE_COUNT\"];\r\n        }\r\n        \r\n        $PStgReader.Close();\r\n\r\n        # Mark persistent staging check to fail if the amount of affected accounts (keys), the amount of generated persistent staging history rows, or the amount of rows marked as PersistentDeleted is not as expected\r\n        If (($AccountCount -ne $RefAccountCount) -or ($RowCount -ne $RefRowCount) -or ($PStgDelCount -ne $RefPstgDelCount)) {\r\n            $PStgCheckResult = 1;\r\n        } else {\r\n            # Attempt to check if DGStartDate in DATA / METADATA table match LoadDateTime in staging tables\r\n            $ReconCheck.CommandText = \"SELECT COUNT(*) AS DATEMATCHED FROM $Schema.LM__$($ObjectPrefix + \"__DATA\") s INNER JOIN $StgSchema.LM__$($ObjectPrefix + \"__DATA\") r ON s.AccountBK = r.AccountBK AND s.DGStartDate = r.LoadDateTime\";\r\n            $DataDateReader = $ReconCheck.ExecuteReader();\r\n\r\n            $DataDateReader.Read() | Out-Null;\r\n            $DataDateMatched = $DataDateReader[\"DATEMATCHED\"];\r\n            \r\n            $DataDateReader.Close();\r\n\r\n            $ReconCheck.CommandText = \"SELECT COUNT(*) AS DATEMATCHED FROM $Schema.LM__$($ObjectPrefix + \"__METADATA\") s INNER JOIN $StgSchema.LM__$($ObjectPrefix + \"__METADATA\") r ON s.AccountBK = r.AccountBK AND s.DGStartDate = r.LoadDateTime\";\r\n            $MetadataDateReader = $ReconCheck.ExecuteReader();\r\n\r\n            $MetadataDateReader.Read() | Out-Null;\r\n            $MetadataDateMatched = $MetadataDateReader[\"DATEMATCHED\"];\r\n            \r\n            $MetadataDateReader.Close();\r\n\r\n            # Mark date matched check to fail if the amount of rows that have DGStartDate in DATA / METADATA tables matches LoadDateTime from staging tables doesn't meet expectation\r\n            If (($DataDateMatched -ne $RefDataDateMatched) -and ($MetadataDateMatched -ne $RefMetadataDateMatched)) {\r\n                $DateMatchedCheckResult = 1;\r\n            } else {\r\n                # Attempt to check if loaded data and status can match expected results\r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ResultTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable) Src\";\r\n                $ResultReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ResultReconReader.Read() | Out-Null;\r\n                $ResultVarianceCount = $ResultReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ResultReconReader.Close();\r\n                \r\n                $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ERTable EXCEPT SELECT LM__STATUS,$($ExpectedCol.Replace(\"\"'\"\",\"\"\"\")) FROM $ResultTable) Src\";\r\n                $ERReconReader = $ReconCheck.ExecuteReader();\r\n                \r\n                $ERReconReader.Read() | Out-Null;\r\n                $ERVarianceCount = $ERReconReader[\"VARIANCECOUNT\"];\r\n                \r\n                $ERReconReader.Close();\r\n                \r\n                # Mark data check to fail if the data or status not meet expectation\r\n                If (($ERVarianceCount -ne 0) -and ($ResultVarianceCount -ne 0)) {\r\n                    $DataCheckResult = 1;\r\n                }\r\n            }\r\n        }\r\n    }\r\n\r\n    # Obtain result from above checks\r\n    $ActualResult = $ObjectCheckResult + $PStgCheckResult + $DateMatchedCheckResult + $DataCheckResult;\r\n\r\n    # Obtain designed result from test case reference\r\n    $LogOutput.CommandText = \"SELECT DesignedResult FROM Monitor.MonitorTestReference WHERE TestCaseID = '$TestCaseID'\";\r\n    $ResultReader = $LogOutput.ExecuteReader();\r\n    \r\n    $ResultReader.Read() | Out-Null;\r\n    $DesignedResult = $ResultReader[\"DesignedResult\"];\r\n    \r\n    $ResultReader.Close();\r\n    \r\n    # Compare actual result to designed result, output the test result and error description (if any)\r\n    If ($ActualResult -eq $DesignedResult) {\r\n        $TestResult = \"Pass\";\r\n        $ErrorDesc = \"\";\r\n    } else {\r\n        $TestResult = \"Fail\";\r\n        $ErrorDesc = switch ($true) {\r\n            {($ObjectCheckResult -eq 1)} {\"Cannot find all expected tables and views from persistent staging process for test case $TestCaseID.\"}\r\n            {($DateMatchedCheckResult -eq 1)} {\"Cannot find expected amount of rows that should have DGStartDate in output table matches LoadDatetime in staging table\"}\r\n            {($PStgCheckResult -eq 1)} {\"Persistent Staging process did not performed as expected.\"}\r\n            {($DataCheckResult -eq 1)} {\"Found variance on data compare to the Expected Result data set.\"}\r\n        };\r\n    }\r\n\r\n    # Output execution result to log\r\n    $ExecutionDatetime = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\";\r\n    \r\n    $LogOutput.CommandText = \"INSERT INTO [Monitor].[TestLog] (ExecutionDatetime, OutputConnection, TestCaseID, TestResult, ErrorDescription) VALUES (CAST('\" + $ExecutionDatetime + \"' AS datetime), '\" + $SourceConnection.Options.ConnectionId + \"', '\" + $TestCaseID + \"', '\" + $TestResult + \"', '\" + $ErrorDesc + \"')\";\r\n    $LogOutput.ExecuteNonQuery() | Out-Null;\r\n}\r\n\r\n# Close connections\r\n$OutputConn.Close();\r\n$LogConn.Close();",
      "TaskName": "PSTG - Reconcile with Expected Output Results",
      "ProjectId": 10,
      "ProjectName": null,
      "TaskTypeName": "PowerShell Core",
      "Logging": 1,
      "LastEndPoint": null,
      "PendingEndPoint": null,
      "ParameterNames": "",
      "ParameterDefaults": "",
      "SourceSchema": null,
      "TargetSchema": null,
      "SourceConnectionName": "Monitor Snowflake Output",
      "TargetConnectionName": "Regression Test Logging",
      "SourceFileName": null,
      "TargetFileName": null,
      "SourceClusterName": null,
      "TargetClusterName": null,
      "SourceFileId": null,
      "TargetFileId": null,
      "MaxThreads": 4,
      "ParallelDm": true,
      "PythonEnvironmentName": null,
      "RunWithAgentId": 2,
      "Agent": {
        "AgentId": 2,
        "AgentName": "PerPrd-WEB01.bizdata.local",
        "HostName": "PerPrd-WEB01.bizdata.local",
        "DateCreated": "0001-01-01T00:00:00",
        "DateUpdated": "0001-01-01T00:00:00",
        "HeartBeat": "0001-01-01T00:00:00",
        "Version": null,
        "TaskQueues": null,
        "ConnectionId": null,
        "IsHealthy": false
      },
      "PythonEnvironment": null,
      "SourceConnection": null,
      "TargetConnection": null,
      "SourceCluster": null,
      "TargetCluster": null,
      "LoggingType": null,
      "TaskType": null,
      "TaskTable": [],
      "TaskConnections": []
    },
    {
      "JobName": "03. Reconcile Results",
      "TaskContent": "# Define test case variables\r\n$TestCaseGroup = \"CR\";\r\n$TestCases = @(\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\");\r\n\r\n# Establish database connection to Monitor Output\r\n$OutputConn = $SourceConnection.CreateOpenConnection();\r\n$ReconCheck = $OutputConn.CreateCommand();\r\n\r\n# Establish database connection to Logging database\r\n$LogConn = $TargetConnection.CreateOpenConnection();\r\n$LogOutput = $LogConn.CreateCommand();\r\n\r\n# Obtain database type of current Output connection\r\n$GetType = $OutputConn.GetType();\r\n$OutputDriverType =\r\n    switch ($GetType){\r\n        \"System.Data.SqlClient.SqlConnection\" {\"Microsoft SQL Server\"}\r\n        \"Snowflake.Data.Client.SnowflakeDbConnection\" {\"Snowflake\"}\r\n    };\r\n\r\n# Start reconciliation process with the loop on test cases\r\nForeach($TestCase in $TestCases) {\r\n    # Provide Basic Test Case information\r\n    $ProjectName = \"INTEGRATION_TEST\";\r\n    $TestCaseID = $TestCaseGroup + $TestCase;\r\n    $RuleId = -1;\r\n    \r\n    # Obtain RuleID of target Monitor Rule for related test case\r\n    $ReconCheck.CommandText = \"SELECT PROJECTID, RULEID FROM LM__REF.LM__MAPPING WHERE ProjectName = '$ProjectName' AND RuleName LIKE '$($TestCaseID + \"_%\")'\";\r\n    $RuleReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $RuleReader.Read() | Out-Null;\r\n    $RuleID = $RuleReader[\"RULEID\"];\r\n    $ProjectID = $RuleReader[\"PROJECTID\"];\r\n    \r\n    $RuleReader.Close();\r\n\r\n    # Define test variables\r\n    $ObjectPrefix = $RuleID.ToString();\r\n    $Schema = \"LM__$ProjectID\";\r\n    $MetadataCols = \"'TaskExecutionId','LoadDateTime','DgRowHash','DGStartDate','PersistDeleted'\";\r\n    $ExpectedCol = switch ($TestCaseID) {\r\n        \"CR3\" {\"TargetConnection,TestCaseID,TestResult,ResultFlg\"}\r\n        \"CR6\" {\"OrderID,OrderDetailID,TransactionDate,UnitPriceDiscount,DiscountedFlg\"}\r\n        Default {\"AccountBK,ParentAccountBK,AccountDescription,AccountType,Operator,ValueType\"}\r\n    };\r\n    $Joincondition = switch ($TestCaseID) {\r\n        \"CR3\" {\"r.TargetConnection = c.TargetConnection AND r.TestCaseID = c.TestCaseID\"}\r\n        \"CR6\" {\"r.OrderID = c.OrderID AND r.OrderDetailID = c.OrderDetailID\"}\r\n        Default {\"r.AccountBK = c.AccountBK\"}\r\n    };\r\n    $ResultTable = \"[$Schema].[LM__$($ObjectPrefix + \"__RESULTS\")]\";\r\n    $CommTable = \"[$Schema].[LM__$($ObjectPrefix + \"__COMMUNICATIONS\")]\";\r\n    $ERTable = \"[Monitor].[Monitor_$($TestCaseID)_ER]\";\r\n\r\n    # Convert test variables for Snowflake Output\r\n    if ($OutputDriverType -eq \"Snowflake\") {\r\n        $Schema = $Schema.ToUpper();\r\n        $MetadataCols = $MetadataCols.ToUpper();\r\n        $ExpectedCol = $ExpectedCol.ToUpper();\r\n        $ResultTable = $ResultTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $CommTable = $CommTable.ToUpper().Replace(\"[\",'\"').Replace(\"]\",'\"');\r\n        $ERTable = \"\"\"Monitor\"\".\"\"MONITOR_$($TestCaseID)_ER\"\"\";\r\n    }\r\n\r\n    # Define expected result reference\r\n    $RefObjectCount = 13;\r\n    $RefRowCount = switch ($TestCaseID) {\r\n        \"CR1\" {12}\r\n        \"CR2\" {7}\r\n        \"CR3\" {18}\r\n        \"CR4\" {3}\r\n        \"CR5\" {3}\r\n        \"CR6\" {1}\r\n        \"CR7\" {99}\r\n    };\r\n    $RefRecipientCount = switch ($TestCaseID) {\r\n        \"CR7\" {3}\r\n        Default {1}\r\n    };\r\n\r\n    #Default check result variables to 0\r\n    $ObjectCheckResult = 0;\r\n    $CommCheckResult = 0;\r\n    $DataCheckResult = 0;\r\n    \r\n    # Attempt to check if all related persistent staging objects were created in Monitor Output\r\n    $ReconCheck.CommandText = switch ($OutputDriverType) {\r\n        \"Snowflake\" {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"\\\\__%\")' ESCAPE '\\\\'\"}\r\n        default {\"SELECT COUNT(TABLE_NAME) AS OBJ_AMOUNT FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA IN ('$Schema', 'DGStg') AND TABLE_NAME LIKE 'LM__$($ObjectPrefix + \"__%\")'\"}\r\n    };\r\n    $ObjectReader = $ReconCheck.ExecuteReader();\r\n    \r\n    $ObjectReader.Read() | Out-Null;\r\n    $ObjectCount = $ObjectReader[\"OBJ_AMOUNT\"];\r\n    \r\n    $ObjectReader.Close();\r\n    \r\n    # Mark object check to fail if the amount of persistent staging objects do not match expected number\r\n    If ($ObjectCount -ne $RefObjectCount)\r\n    {\r\n        $ObjectCheckResult = 1;\r\n    } else {\r\n        # Attempt to check if communication are processed as expected\r\n        $ReconCheck.CommandText = \"SELECT COUNT(*) AS ROW_COUNT, COUNT(DISTINCT LM__RECIPIENT) AS RECIPIENT_COUNT FROM $CommTable\";\r\n        $CommReader = $ReconCheck.ExecuteReader();\r\n        \r\n        While ($CommReader.Read()) {\r\n            $RowCount = $CommReader[\"ROW_COUNT\"];\r\n            $RecipientCount = $CommReader[\"RECIPIENT_COUNT\"];\r\n        }\r\n        \r\n        $CommReader.Close();\r\n\r\n        # Mark communication check to fail if either amount of rows meet branching logic or the amount of email recipients is not as expected\r\n        If (($RowCount -ne $RefRowCount) -or ($RecipientCount -ne $RefRecipientCount)) {\r\n            $CommCheckResult = 1;\r\n        } else {\r\n            # Attempt to check if loaded data and status can match expected results\r\n            $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$(\"r.\" + $ExpectedCol.Replace(\",\", \",r.\")),CASE WHEN c.LM__RECIPIENT IS NOT NULL THEN 1 ELSE 0 END AS CommFlg, COALESCE(LM__CHANNEL, NULL) AS CommChannel FROM $ResultTable r LEFT JOIN $CommTable c ON $Joincondition EXCEPT SELECT LM__STATUS,$(if ($TestCaseID -eq \"CR5\") {$ExpectedCol.Replace(\"ParentAccountBK\", \"COALESCE(ParentAccountBK,'') AS ParentAccountBK\")} else {$ExpectedCol}),CommFlg,CommChannel FROM $ERTable) Src\";\r\n            $ResultReconReader = $ReconCheck.ExecuteReader();\r\n            \r\n            $ResultReconReader.Read() | Out-Null;\r\n            $ResultVarianceCount = $ResultReconReader[\"VARIANCECOUNT\"];\r\n            \r\n            $ResultReconReader.Close();\r\n            \r\n            $ReconCheck.CommandText = \"SELECT COUNT(*) AS VARIANCECOUNT FROM (SELECT LM__STATUS,$(if ($TestCaseID -eq \"CR5\") {$ExpectedCol.Replace(\"ParentAccountBK\", \"COALESCE(ParentAccountBK,'') AS ParentAccountBK\")} else {$ExpectedCol}),CommFlg,CommChannel FROM $ERTable EXCEPT SELECT LM__STATUS,$(\"r.\" + $ExpectedCol.Replace(\",\", \",r.\")),CASE WHEN c.LM__RECIPIENT IS NOT NULL THEN 1 ELSE 0 END AS CommFlg, COALESCE(LM__CHANNEL, NULL) AS CommChannel FROM $ResultTable r LEFT JOIN $CommTable c ON $Joincondition) Src\";\r\n            $ERReconReader = $ReconCheck.ExecuteReader();\r\n            \r\n            $ERReconReader.Read() | Out-Null;\r\n            $ERVarianceCount = $ERReconReader[\"VARIANCECOUNT\"];\r\n            \r\n            $ERReconReader.Close();\r\n\r\n            # Mark data check to fail if the data or status not meet expectation\r\n            If (($ERVarianceCount -ne 0) -and ($ResultVarianceCount -ne 0)) {\r\n                $DataCheckResult = 1;\r\n            }\r\n        }\r\n    }\r\n\r\n    # Obtain result from above checks\r\n    $ActualResult = $ObjectCheckResult + $CommCheckResult + $DataCheckResult;\r\n\r\n    # Obtain designed result from test case reference\r\n    $LogOutput.CommandText = \"SELECT DesignedResult FROM Monitor.MonitorTestReference WHERE TestCaseID = '$TestCaseID'\";\r\n    $ResultReader = $LogOutput.ExecuteReader();\r\n    \r\n    $ResultReader.Read() | Out-Null;\r\n    $DesignedResult = $ResultReader[\"DesignedResult\"];\r\n    \r\n    $ResultReader.Close();\r\n    \r\n    # Compare actual result to designed result, output the test result and error description (if any)\r\n    If ($ActualResult -eq $DesignedResult) {\r\n        $TestResult = \"Pass\";\r\n        $ErrorDesc = \"\";\r\n    } else {\r\n        $TestResult = \"Fail\";\r\n        $ErrorDesc = switch ($true) {\r\n            {($ObjectCheckResult -eq 1)} {\"Cannot find all expected tables and views from persistent staging process for test case $TestCaseID.\"}\r\n            {($CommCheckResult -eq 1)} {\"Communication is not processed as expected.\"}\r\n            {($DataCheckResult -eq 1)} {\"Found variance on data compare to the Expected Result data set.\"}\r\n        };\r\n    }\r\n\r\n    # Output execution result to log\r\n    $ExecutionDatetime = Get-Date -Format \"yyyy-MM-dd HH:mm:ss\";\r\n    \r\n    $LogOutput.CommandText = \"INSERT INTO [Monitor].[TestLog] (ExecutionDatetime, OutputConnection, TestCaseID, TestResult, ErrorDescription) VALUES (CAST('\" + $ExecutionDatetime + \"' AS datetime), '\" + $SourceConnection.Options.ConnectionId + \"', '\" + $TestCaseID + \"', '\" + $TestResult + \"', '\" + $ErrorDesc + \"')\";\r\n    $LogOutput.ExecuteNonQuery() | Out-Null;\r\n}\r\n\r\n# Close connections\r\n$OutputConn.Close();\r\n$LogConn.Close();",
      "TaskName": "CR - Reconcile with Expected Output Results",
      "ProjectId": 10,
      "ProjectName": null,
      "TaskTypeName": "PowerShell Core",
      "Logging": 1,
      "LastEndPoint": null,
      "PendingEndPoint": null,
      "ParameterNames": "",
      "ParameterDefaults": "",
      "SourceSchema": null,
      "TargetSchema": null,
      "SourceConnectionName": "Monitor Snowflake Output",
      "TargetConnectionName": "Regression Test Logging",
      "SourceFileName": null,
      "TargetFileName": null,
      "SourceClusterName": null,
      "TargetClusterName": null,
      "SourceFileId": null,
      "TargetFileId": null,
      "MaxThreads": 4,
      "ParallelDm": true,
      "PythonEnvironmentName": null,
      "RunWithAgentId": 2,
      "Agent": {
        "AgentId": 2,
        "AgentName": "PerPrd-WEB01.bizdata.local",
        "HostName": "PerPrd-WEB01.bizdata.local",
        "DateCreated": "0001-01-01T00:00:00",
        "DateUpdated": "0001-01-01T00:00:00",
        "HeartBeat": "0001-01-01T00:00:00",
        "Version": null,
        "TaskQueues": null,
        "ConnectionId": null,
        "IsHealthy": false
      },
      "PythonEnvironment": null,
      "SourceConnection": null,
      "TargetConnection": null,
      "SourceCluster": null,
      "TargetCluster": null,
      "LoggingType": null,
      "TaskType": null,
      "TaskTable": [],
      "TaskConnections": []
    }
  ],
  "JobSequences": [
    {
      "JobName": "03. Reconcile Results",
      "RunSequence": 1,
      "ParallelSequence": 0,
      "ParameterValues": null,
      "ConnectionId": null,
      "Active": true,
      "TaskName": "SQ - Reconcile with Expected Output Results",
      "Connection": null
    },
    {
      "JobName": "03. Reconcile Results",
      "RunSequence": 2,
      "ParallelSequence": 0,
      "ParameterValues": null,
      "ConnectionId": null,
      "Active": true,
      "TaskName": "KC - Reconcile with Expected Output Results",
      "Connection": null
    },
    {
      "JobName": "03. Reconcile Results",
      "RunSequence": 3,
      "ParallelSequence": 0,
      "ParameterValues": null,
      "ConnectionId": null,
      "Active": true,
      "TaskName": "RR - Reconcile with Expected Output Results",
      "Connection": null
    },
    {
      "JobName": "03. Reconcile Results",
      "RunSequence": 4,
      "ParallelSequence": 0,
      "ParameterValues": null,
      "ConnectionId": null,
      "Active": true,
      "TaskName": "PSTG - Reconcile with Expected Output Results",
      "Connection": null
    },
    {
      "JobName": "03. Reconcile Results",
      "RunSequence": 5,
      "ParallelSequence": 0,
      "ParameterValues": null,
      "ConnectionId": null,
      "Active": true,
      "TaskName": "CR - Reconcile with Expected Output Results",
      "Connection": null
    }
  ],
  "JobSequenceDependencies": [],
  "JobDependencies": []
}